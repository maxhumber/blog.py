---
title: 'Starry Night Plots'
tags: [r]
output: html_document
    # md_document:
    #   variant: markdown_github
---

```{r, warning = FALSE, message = FALSE, include = FALSE}
library(knitr)

opts_chunk$set(
    cache = TRUE, warning = FALSE, message = FALSE, dpi = 150, fig.show = "animate")
```

I think good data science reads like a good story. In that it flows. Has an arc. And is compelling. 

But data science has a dirty secret. For every piece that works, there are about nine others that didn't. Nine other stories that look like they were typed up by a monkey with a typewriter (and with a [finite amount](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) time!)

The problem with this problem is that unless you did the work you never get to see the monkey scripts. The stuff that never worked. The stuff that got thrown out. 

This creates, I think, unrealistic expectations about how data science gets done. Because every tutorial, textbook, lesson, workshop, talk, and blog post about data science just works. And we forget that this stuff has been designed and vetted to work. Most real world stuff doesn't just work. 

I initially wanted this post to be about the Super Bowl. To build some model on `Average Points For` and `Against` and push it through a new plot that I've been working on. But nothing was working. The data and my model told a story that literally made zero sense.

But then it struck me. This is perfect. I was able to catch and diagnose a garbage model exactly because of the plot I wanted to talk about. So. Here's my monkey script and the Starry Night Plot that helped me throw it out:

## SETUP

```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(viridis)
```

```{r include = FALSE}
library(stringr)
library(purrr)
library(rvest)

# scrape and format data

pfr <- tribble(
    ~team, ~ticker,
    "Arizona Cardinals", "crd",
    "Atlanta Falcons", "atl",
    "Baltimore Ravens", "rav",
    "Buffalo Bills", "buf",
    "Carolina Panthers", "car",
    "Chicago Bears", "chi",
    "Cincinnati Bengals", "cin",
    "Cleveland Browns", "cle",
    "Dallas Cowboys", "dal",
    "Denver Broncos", "den",
    "Detroit Lions", "det",
    "Green Bay Packers", "gnb",
    "Houston Texans", "htx",
    "Indianapolis Colts", "clt",
    "Jacksonville Jaguars", "jax",
    "Kansas City Chiefs", "kan",
    "Los Angeles Rams", "ram",
    "Miami Dolphins", "mia",
    "Minnesota Vikings", "min",
    "New England Patriots", "nwe",
    "New Orleans Saints", "nor",
    "New York Giants", "nyg",
    "New York Jets", "nyj",
    "Oakland Raiders", "rai",
    "Philadelphia Eagles", "phi",
    "Pittsburgh Steelers", "pit",
    "San Diego Chargers", "sdg",
    "San Francisco 49ers", "sfo",
    "Seattle Seahawks", "sea",
    "Tampa Bay Buccaneers", "tam",
    "Tennessee Titans", "oti",
    "Washington Redskins", "was")

ticker <- pfr %>% 
    select(ticker) %>% 
    t(.) %>% 
    as.vector(.)

params <- expand.grid(ticker = ticker, year = 2002:2016) %>% 
    mutate(ticker = as.character(ticker))

scrape_pfr <- function(ticker = "atl", year = 2016) {
    
    url <- str_c(
        "http://www.pro-football-reference.com/teams/", 
        ticker, "/", year, ".htm")
    
    page <- read_html(url)
    
    record <- page %>%
        html_nodes(".prevnext+ p") %>% 
        html_text() 
    
    pf <- page %>%
        html_nodes("#meta p:nth-child(5)") %>% 
        html_text() 
    
    pa <- page %>%
        html_nodes("#meta p:nth-child(6)") %>% 
        html_text() 
    
    expected <- page %>%
        html_nodes("#meta p:nth-child(7)") %>% 
        html_text() 
    
    comp <- page %>%
        html_nodes("#meta p:nth-child(8)") %>% 
        html_text() 
    
    df <- tibble(ticker, year, record, pf, pa, expected, comp)
    
    return(df)
}

pfr_data <- params %>% 
    pmap(scrape_pfr) %>% 
    bind_rows()

# cache

write_csv(pfr_data, "pfr_data.csv")
pfr_data <- read_csv("pfr_data.csv")

# reformat

record <- pfr_data %>% 
    mutate(srs = comp) %>% 
    mutate(srs = str_replace(srs, "^[^\\:\\s]*\\:\\s", "")) %>% 
    mutate(srs = str_replace(srs, "\\(.*", "")) %>% 
    mutate(srs = str_replace(srs, "\\sSOS.*$", "")) %>% 
    mutate(srs = parse_number(srs)) %>% 
    mutate(pa = str_replace(pa, "\\/.*$", "")) %>% 
    mutate(pa = str_replace(pa, "^(.*?\\()", "")) %>% 
    mutate(pf = str_replace(pf, "\\/.*$", "")) %>% 
    mutate(pf = str_replace(pf, "^(.*?\\()", "")) %>% 
    mutate(pf = as.numeric(pf), pa = as.numeric(pa)) %>% 
    select(ticker, year, srs, pf, pa) %>%
    left_join(pfr, by = "ticker")

# super bowl collection

superbowl <- tribble(
    ~superbowl, ~winner, ~loser,
    50, "Denver Broncos", "Carolina Panthers", 
    49, "New England Patriots", "Seattle Seahawks", 
    48, "Seattle Seahawks", "Denver Broncos", 
    47, "Baltimore Ravens", "San Francisco 49ers", 
    46, "New York Giants", "New England Patriots",
    45, "Green Bay Packers", "Pittsburgh Steelers",
    44, "New Orleans Saints", "Indianapolis Colts",
    43, "Pittsburgh Steelers", "Arizona Cardinals",
    42, "New York Giants", "New England Patriots",
    41, "Indianapolis Colts", "Chicago Bears",
    40, "Pittsburgh Steelers", "Seattle Seahawks",
    39, "New England Patriots", "Philadelphia Eagles",
    38, "New England Patriots", "Carolina Panthers",
    37, "Tampa Bay Buccaneers", "Oakland Raiders"
    ) %>% 
    mutate(year_superbowl = 1966 + superbowl) %>% 
    mutate(year_season = year_superbowl - 1) %>% 
    select(-year_superbowl)

# final format

superbowl_data <- superbowl %>% 
    gather(result, team, -superbowl, -year_season) %>% 
    left_join(record, by = c("team", "year_season" = "year")) %>% 
    mutate(win = ifelse(result == "winner", 1, 0)) %>% 
    select(superbowl, year_season, team, win, pf, pa, srs)

# cache final form
write_csv(superbowl_data, "superbowl_data.csv")
superbowl_data <- read_csv("superbowl_data.csv")
```

## DATA

These data are scraped from [pro-football-reference.com](http://www.pro-football-reference.com/) with `purrr` and `rvest`. If you want to learn more about webscraping with the tidverse I have a quick post about it [here](http://maxhumber.com/2017/01/08/vorp-hockey.html). And if you want to see exactly how I got these data the full 

```{r}
df <- read_csv(paste0(
    "https://raw.githubusercontent.com/maxhumber/",
    "maxhumber.com/master/assets/data/superbowl_data.csv"))
```

```{r}
mod1 <- glm(
    win ~ pf + pa,
    family = "binomial",
    data = df)

summary(mod1)
```

```{r}
pred_grid <- expand.grid(
    pf = 0:40, 
    pa = 0:40)

pred_grid$prob <- predict(mod1, newdata = pred_grid, type = "response")
```





Really wanted to write somethng for super bowl.
don't really know anything about football.. but will watch

tried to precit who will will


Model diagnoistics
visualizatior diagnotistics
pred grid

p-hacking .... could have find something.
looking at pvalues and like... ooop!

wanted to tell a story,


```{r}
contour(x = pred_grid$pf, y = pred_grid$pa, z = pred_grid$prob)
```

```{r}
pred_grid %>% 
    ggplot(aes(x = pf, y = pa)) + 
    geom_tile(aes(fill = prob))
```



```{r}
br <- 0.2

pred_grid %>% 
    ggplot(aes(x = pf, y = pa)) + 
    geom_tile(aes(fill = prob)) + 
    geom_contour(aes(z = prob), color = "white", lty = 2, binwidth = br) +
    geom_point(
        data = (df %>% filter(win == 1)),
        color = "white", shape = 16, size = 2) +
    geom_point(
        data = (df %>% filter(win == 0)),
        color = "white", shape = 4, size = 2) +
    scale_fill_viridis(
        direction = 1, end = 0.85, option = "D", 
        breaks = seq(0, 1, br),
        labels = scales::percent_format()) + 
    coord_cartesian(xlim = c(10, 40), ylim = c(10, 40))
```

```{r}
df2 <- df %>% 
    select(year_season, team, win, pf, pa) %>% 
    arrange(year_season)
```







